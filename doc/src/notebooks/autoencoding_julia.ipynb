{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-encoding of Julia Source Code\n",
    "\n",
    "We investigate the ability of deep neural network architectures to capture key syntactic and semantic information in Julia source code using relatively low-dimensional representations. These representations can be potentially very powerful tools for automated program analysis and curation, especially across heterogeneous research fields and repositories. \n",
    "\n",
    "There is in fact a wealth of [research](https://github.com/src-d/awesome-machine-learning-on-source-code) in this area, though to date there has been no application of these ideas or approaches to the Julia language itself. In this experiment, we study the makeup and patterns of the base Julia language source code in the hopes of identifying futher avenues of research. \n",
    "\n",
    "We use the Keras deep learning API to construct our autoencoding model, and Numpy and Pandas libraries to manage the data inputs and outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, GRU, RepeatVector, Activation, CuDNNGRU\n",
    "from keras.layers import Dense, BatchNormalization, Embedding\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the lower-dimensional representation we wish to create is a somewhat arbitrary choice; we chose 64 dimensions as a reasonably rich but still manageable number. Identifying optimal dimensionality is an area for further research. \n",
    "\n",
    "We read our saved code snippets and source filepath labels in to a Pandas DataFrame. We also truncate any path information above the Julia repo itself as irrelevant (and necessarily uniformly repeated). Given large number of unique sources filepaths (546) and the low number of snippets in the median source file (19), we compute two aggregated groups of source files: top-level folders in the Julia repo and second-level divisions, which include both folders (with multiple files and folders within them) as well as single source code files in the top level folders themselves. \n",
    "\n",
    "There are 7 top level folders with a wide range of amount of code within each, and 273 second-level divisions:\n",
    "\n",
    "```\n",
    "test               9391\n",
    "stdlib             7846\n",
    "base               7486\n",
    "doc                  30\n",
    "contrib              25\n",
    "src                   7\n",
    "etc                   2\n",
    "\n",
    "base_gcutils          5\n",
    "base_array          170\n",
    "test_meta            70\n",
    "test_spawn           85\n",
    "test_project          8\n",
    "test_stacktraces     12\n",
    "base_sysinfo         34\n",
    "[...]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "with open(\"all_funcs.csv\", \"r\") as f: \n",
    "    funcs = f.read()\n",
    "\n",
    "funcs = funcs.split(\".jl\\n\")\n",
    "funcs = funcs[:-1] # remove trailing empty item\n",
    "funcs = pd.DataFrame([x.rsplit(\"\\t\",1) for x in funcs])\n",
    "funcs.columns = ['code','source']\n",
    "funcs = funcs[funcs.code.apply(lambda x: len(x)<=500)]\n",
    "funcs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "funcs.source = funcs.source.apply(lambda x: x[x.index(\"julia/\")+6:])\n",
    "funcs[\"top_folder\"] = funcs.source.apply(lambda x: x[:x.index(\"/\")])\n",
    "funcs['top2'] = funcs.source.apply(lambda x: '_'.join(x.split(\"/\")[:2]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with a common sequence-to-sequence modeling approach as represented by [recent work](https://towardsdatascience.com/how-to-create-data-products-that-are-magical-using-sequence-to-sequence-models-703f86a231f8) at GitHub itself. This system was originally built to summarize Github issues, using the issue text as input sequences and issue titles as the target sequences. We adapt this to use as an auto-encoding system by using the same source code snippets as both inputs and targets. \n",
    "<img src=\"../img/autoenc_diagram.png\" />\n",
    "\n",
    "_(Please note, if you have Keras v. 2.2.4 installed that there is an issue with the accuracy calculation (https://github.com/keras-team/keras/issues/11749). This is resolvable by upgrading to the latest version available via git or by downgrading to an earlier version of Keras. Given that the problem is already fixed in the latest unreleased code, we expect this issue to be resolved in the next pip-able release as well (i.e., 2.2.5).)_\n",
    "\n",
    "We define two utility functions to aid in our encoding: `chars_to_indices()` which translates Julia source code into integers representing each character, and `ae_models` which build our autoencoder architecture. This second function returns two models - the full autoencoder, as well as the encoder sub-component. We use this second model to encode our Julia source code sequences after training is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chars_to_indices(data, tok=None, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = max(data.apply(lambda x: len(x)))\n",
    "\n",
    "    if tok is None:\n",
    "        tok = Tokenizer(num_words=None, \n",
    "                        filters=\"\", \n",
    "                        lower=False, \n",
    "                        split='', \n",
    "                        char_level=True)\n",
    "\n",
    "    data = data.values\n",
    "    tok.fit_on_texts(data)\n",
    "    sequences = tok.texts_to_sequences(data)\n",
    "    sequences = pad_sequences(sequences, \n",
    "                              maxlen=max_len, \n",
    "                              padding='post')\n",
    "    sequences = np.array(sequences, dtype='int16')\n",
    "\n",
    "    return sequences, tok\n",
    "\n",
    "def ae_models(maxlen, latent_dim, N, use_gpu=False):\n",
    "    inputs = Input((maxlen,), name='Encoder_Inputs')\n",
    "    encoded = Embedding(N, \n",
    "                        latent_dim, \n",
    "                        name='Char_Embedding', \n",
    "                        mask_zero=False)(inputs)\n",
    "    encoded = BatchNormalization(name='BatchNorm_Encoder')(encoded)\n",
    "\n",
    "    if use_gpu:\n",
    "        _, state_h = CuDNNGRU(latent_dim, return_state=True)(encoded)\n",
    "    else:\n",
    "        _, state_h = GRU(latent_dim, return_state=True)(encoded)\n",
    "\n",
    "    enc = Model(inputs=inputs, outputs=state_h, name='Encoder_Model')\n",
    "    enc_out = enc(inputs)\n",
    "\n",
    "    dec_inputs = Input(shape=(None,), name='Decoder_Inputs')\n",
    "    decoded = Embedding(N, \n",
    "                        latent_dim, \n",
    "                        name='Decoder_Embedding', \n",
    "                        mask_zero=False)(dec_inputs)\n",
    "    decoded = BatchNormalization(name='BatchNorm_Decoder_1')(decoded)\n",
    "\n",
    "    if use_gpu:\n",
    "        dec_out, _ = CuDNNGRU(latent_dim, \n",
    "                              return_state=True, \n",
    "                              return_sequences=True)(decoded, initial_state=enc_out)\n",
    "    else:\n",
    "        dec_out, _ = GRU(latent_dim, \n",
    "                         return_state=True, \n",
    "                         return_sequences=True)(decoded, initial_state=enc_out)\n",
    "\n",
    "    dec_out = BatchNormalization(name='BatchNorm_Decoder_2')(dec_out)\n",
    "    dec_out = Dense(N, activation='softmax', name='Final_Out')(dec_out)\n",
    "\n",
    "    sequence_autoencoder = Model(inputs=[inputs, dec_inputs], outputs=dec_out)\n",
    "\n",
    "    return sequence_autoencoder, enc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert our Julia code snippets to vectors of integers, tokenized at the character level. E.g.,\n",
    "\n",
    "```Julia\n",
    "a::BitSet âŠŠ b::BitSet = begin\n",
    "        #= none:414 =#\n",
    "        a <= b && a != b\n",
    "    end\n",
    "```\n",
    "    \n",
    "becomes:\n",
    "\n",
    "```Python\n",
    "array([ 11,   8,   8,  52,   9,   4,  48,   2,   4,   1, 135,   1,  28,\n",
    "         8,   8,  52,   9,   4,  48,   2,   4,   1,   5,   1,  28,   2,\n",
    "        24,   9,   3,  13,   1,   1,   1,   1,   1,   1,   1,   1,  10,\n",
    "         5,   1,   3,   6,   3,   2,   8,  37,  21,  37,   1,   5,  10,\n",
    "        13,   1,   1,   1,   1,   1,   1,   1,   1,  11,   1,  65,   5,\n",
    "         1,  28,   1,  76,  76,   1,  11,   1,  67,   5,   1,  28,  13,\n",
    "         1,   1,   1,   1,   2,   3,  17])```\n",
    "\n",
    "There are 235 unique characters in our Julia source code data (343 in the entire source code corpus, though over 100 of these are contained solely in a handful of excessively long expressions that were excluded for this experiment). To leverage teacher forcing in our seq2seq autoencoder training, we include the original input sequence as an input to the decoder portion of the autoencoder, and our target output is the the same input sequence one character offset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs, tok = chars_to_indices(funcs.iloc[:,0])\n",
    "N = len(np.unique(seqs))\n",
    "\n",
    "decoder_inputs = seqs[:,  :-1]\n",
    "Y = seqs[:, 1:  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then build our model. The system can be set to run on a GPU or a CPU, depending on the hardware available. On an Nvidia Quadro P4000 training this model takes roughly 50 seconds per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Embedding (Embedding)   (None, None, 64)     15040       Decoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_Inputs (InputLayer)     (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_Decoder_1 (BatchNorma (None, None, 64)     256         Decoder_Embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_Model (Model)           (None, 64)           40064       Encoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     [(None, None, 64), ( 24768       BatchNorm_Decoder_1[0][0]        \n",
      "                                                                 Encoder_Model[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_Decoder_2 (BatchNorma (None, None, 64)     256         gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Final_Out (Dense)               (None, None, 235)    15275       BatchNorm_Decoder_2[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 95,659\n",
      "Trainable params: 95,275\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# autoencoder, enc = ae_models(max_len, 64, N, use_gpu=True)\n",
    "autoencoder, enc = ae_models(500, 64, 235, use_gpu=False)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that Adam optimization with amsgrad gave the best results for training efficiency and accuracy. We use sparse categorical crossentropy as our loss function, with the aim to reproduce input code snippets as exactly as possible in our outputs, character by character, over the 235-character \"vocabulary.\"\n",
    "\n",
    "We train for up to 100 epochs, using a batch size of 32 and validating on 12% of the total data. We also use early stopping to settle on an optimal set of model weights should learning level out before the 100th epoch. In various tests this was always the case, with our final model achieving a 93% level of per-character accuracy on the 44th epoch. In some cases it is useful to reduce the learning rate to 0.0001 after the first training session has stopped, but in our experiment this did not improve the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001, amsgrad=True)\n",
    "\n",
    "autoencoder.compile(loss='sparse_categorical_crossentropy',\n",
    "                    optimizer=opt,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc',\n",
    "                          min_delta=0.0001,\n",
    "                          patience=10,\n",
    "                          verbose=1,\n",
    "                          mode='auto',\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "autoencoder.fit([seqs, decoder_inputs],\n",
    "                np.expand_dims(Y, -1),\n",
    "                epochs = 100,\n",
    "                batch_size = 32,\n",
    "                validation_split=0.12,\n",
    "                callbacks=[early_stop],\n",
    "                shuffle=True)\n",
    "\n",
    "autoencoder.save(\"autoencoder.h5\")\n",
    "enc.save(\"encoder.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode our Julia source code snippet sequences with our newly trained encoder model. This gives us a two-dimensional Numpy array of shape (24787, 64) - each snippet being one row, represented as a vector of 64 float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_reps = enc.predict(seqs)\n",
    "encoded_reps = pd.DataFrame(encoded_reps)\n",
    "\n",
    "encoded_reps.to_csv(\"encoded_reps.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Analysis\n",
    "We use Python's `matplotlib` library for plotting our visualizations, and [`UMAP`](https://arxiv.org/abs/1802.03426) (Uniform Manifold Approximation and Projection for Dimension Reduction) to represent our findings in a two-dimensional space. We also include code to produce three-dimensional interactive visualizations which can be even more informative, but the interactivity is beyond the scope of this static notebook documentation.\n",
    "\n",
    "UMAP is a novel manifold learning technique for dimension reduction constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The UMAP algorithm is competitive with the popular t-SNE method for visualization quality, while seeking to preserve more of the global structure with superior run time performance.\n",
    "\n",
    "For visualizing our findings here, we limit our test to the \"base\" top-level folder (7486 code snippets), and label our cases by their second-level folder/file. We further limit our test cases to those labels with at least 100 examples for better visualization and comparison (21 categories).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "import sklearn.cluster as cluster\n",
    "from umap import UMAP\n",
    "\n",
    "X_test = encoded_reps[funcs.top_folder==\"base\"]\n",
    "Y_test = funcs.top2[funcs.top_folder==\"base\"]\n",
    "code_test = funcs.code[funcs.top_folder==\"base\"]\n",
    "top_cats = list(Y_test.value_counts()[Y_test.value_counts()>=100].index)\n",
    "\n",
    "X_test = X_test[Y_test.apply(lambda x: x in top_cats)]\n",
    "code_test = code_test[Y_test.apply(lambda x: x in top_cats)]\n",
    "Y_test = Y_test[Y_test.apply(lambda x: x in top_cats)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cosine distance to compare the 64-dimensional vectors for our code snippets, and compute UMAP projections in two- and three-dimensional representations. Cosine distance is a measure of distnace between two vectors of an inner product space that measures the cosine of the angle between them, and is one of the most common distance metrics for comparing sequences in machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = UMAP(random_state=42, \n",
    "               metric='cosine', \n",
    "               n_neighbors=30, \n",
    "               n_components=2)\n",
    "embedding = reducer.fit_transform(X_test)\n",
    "\n",
    "reducer_3d = UMAP(random_state=42, \n",
    "                  metric='cosine', \n",
    "                  n_neighbors=30, \n",
    "                  n_components=3)\n",
    "embedding_3d = reducer_3d.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute silhouette scores, which measure cohesion vs. overlap in multi-dimensional clusters on a scale from -1 (no separation and perfect overlap) to 1 (perfectly separated and compact clusters), both for our latent 64-dimensional space and the two-dimensional UMAP representation for our 21 test categories. We then visualize the UMAP representation (optionally in three dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sils = silhouette_samples(X_test, Y_test, metric='cosine')\n",
    "clusts = pd.concat([X_test.reset_index(drop=True), \n",
    "                    Y_test.reset_index(drop=True), \n",
    "                    pd.Series(sils)], axis=1, ignore_index=True)\n",
    "centroids = clusts.groupby(64).agg('mean').sort_values(65)\n",
    "\n",
    "sils2 = silhouette_samples(embedding, Y_test, metric='cosine')\n",
    "clusts2 = pd.concat([X_test.reset_index(drop=True), \n",
    "                     Y_test.reset_index(drop=True), \n",
    "                     pd.Series(sils2)], axis=1, ignore_index=True)\n",
    "centroids2 = clusts2.groupby(64).agg('mean').sort_values(65)\n",
    "\n",
    "src = list(centroids.index)\n",
    "\n",
    "colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
    "by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgba(color)[:3])), name)\n",
    "                for name, color in colors.items())\n",
    "sorted_names = [name for hsv, name in by_hsv]\n",
    "\n",
    "NUM_COLORS = len(src)\n",
    "step = int(np.floor(len(sorted_names)/NUM_COLORS))\n",
    "my_cols = [sorted_names[i] \n",
    "           for i in range(0, len(sorted_names), step)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "for i, s in enumerate(src):\n",
    "    ax.scatter(embedding[Y_test==s, 0], \n",
    "                embedding[Y_test==s, 1], \n",
    "                c=my_cols[i], \n",
    "                linewidths=0.1,\n",
    "                edgecolors='k',\n",
    "                label=s)\n",
    "plt.setp(ax, xticks=[], yticks=[]) \n",
    "plt.title(\"Julia source code data embedded into two dimensions by UMAP\", \n",
    "          fontsize=18) \n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "plt.subplots_adjust(right=0.75)\n",
    "plt.show()\n",
    "\n",
    "# #\n",
    "# # 3d Plot\n",
    "# # \n",
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# ax2 = fig.add_subplot(111, projection=\"3d\")\n",
    "# for i, s in enumerate(src):\n",
    "#     ax2.scatter(embedding_3d[Y_test==s, 0], \n",
    "#                 embedding_3d[Y_test==s, 1], \n",
    "#                 embedding_3d[Y_test==s, 2], \n",
    "#                 c=my_cols[i], \n",
    "#                 linewidths=0.1,\n",
    "#                 edgecolors='k',\n",
    "#                 label=s)\n",
    "# plt.setp(ax2, xticks=[], yticks=[]) \n",
    "# plt.title(\"Julia source code data embedded into two dimensions by UMAP\", \n",
    "#           fontsize=18) \n",
    "# plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "# plt.subplots_adjust(right=0.75)\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings and Analysis\n",
    "Encoded code snippets sort into several distinct groups based on syntactic and semantic content, but not necessarily in line with their source in the Julia source code directory tree. There is in fact a large degree of overlap across our directory-structure-defined categories. \n",
    "<img src=\"../img/julia_code_map100.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those in base/Base.jl exhibited a great degree of intra-group similarity and cohesion (this group had a silhouette score of 0.74 in the UMAP embedding space, and 0.39 in the auto encoded 64-dimensional representation space). The only other source code group with somewhat similar cohesion was base/docs/ (silhouette of 0.07 in UMAP space, and 0.28 in latent space), while the rest of the top level code groups were far more intermixed with each other.\n",
    "<img src=\"../img/silhouettes.png\" />\n",
    "\n",
    "Using some quick k-means clustering on the UMAP embeddings allows us to zero in on some of these groups and inspect the code snippets for what common content and structures.\n",
    "<img src=\"../img/k_clusts.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters 3, 15, 18, and 37 overlap most significantly with the bulk of code groups base_compiler, base_Base, base_boot, and base_docs, respectively. Looking at example snippets from these clusters shows some obvious consistencies in form and content. \n",
    "\n",
    "Cluster 3 is largely assignments, often of constants, and these would naturally feature prominently in the base_compiler code group. Referenceing our original UMAP projection graphic, it's also unsurprising to see many other code groups featured in cluster 3, as this is a very common type of expression across the Julia language. \n",
    "\n",
    "```Julia\n",
    "primitive type UInt128 <: Unsigned 128 end\n",
    "const UTF8PROC_COMPOSE = 1 << 3\n",
    "const _tvarnames = Symbol[:_A, :_B, :_C, :_D, :_E, :_F, :_G, :_H, :_I, :_J, :_K, :_L, :_M, :_N, :_O, :_P, :_Q, :_R, :_S, :_T, :_U, :_V, :_W, :_X, :_Y, :_Z]\n",
    "const LOG2_E = 1.4426950408889634\n",
    "const DATATYPE_PARAMETERS_FIELDINDEX = fieldindex(DataType, :parameters)```\n",
    "\n",
    "\n",
    "Cluster 15 is largely `include` statements, and again this makes intuitive sense that these would comprise much of the base_Base code snippets. This is very tightly grouped cluster, as these statements are syntacticly simple and very uniform. \n",
    "\n",
    "```Julia\n",
    "include(\"strings/basic.jl\")\n",
    "include(\"process.jl\")\n",
    "include(\"gmp.jl\")\n",
    "include(\"arraymath.jl\")\n",
    "include(\"asyncmap.jl\")```\n",
    "\n",
    "\n",
    "Cluster 18, heavily identified with the base_boot code group, appears to consiste primarily of short type conversion functions. \n",
    "\n",
    "```Julia\n",
    "toUInt16(x::UInt16) = begin\n",
    "        x\n",
    "    end\n",
    "\n",
    "toUInt32(x::UInt8) = begin\n",
    "        zext_int(UInt32, x)\n",
    "    end\n",
    "\n",
    "toInt16(x::Bool) = begin\n",
    "        and_int(zext_int(Int16, x), Int16(1))\n",
    "    end\n",
    "\n",
    "toInt16(x::Int32) = begin\n",
    "        checked_trunc_sint(Int16, x)\n",
    "    end\n",
    "\n",
    "toInt16(x::Int16) = begin\n",
    "        x\n",
    "    end```\n",
    "\n",
    "\n",
    "Finally, Cluster 37, where we find most of our base_docs snippets, consists primarily of doc-string prefaced code snippets. The base_docs code group is almost all doc-strings itself, and thus the tight grouping of its code snippets in this cluster. \n",
    "\n",
    "```Julia\n",
    "\"\"\"\n",
    "    Signed <: Integer\n",
    "\n",
    "Abstract supertype for all signed integers.\n",
    "\"\"\"\n",
    "Signed\n",
    "\n",
    "\"\"\"\n",
    "    copy(x)\n",
    "\n",
    "Create a shallow copy of `x`: the outer structure is copied, but not all internal values.\n",
    "For example, copying an array produces a new array with identically-same elements as the\n",
    "original.\n",
    "\"\"\"\n",
    "copy\n",
    "\n",
    "\"\"\"\n",
    "    cis(z)\n",
    "\n",
    "Return ``\\\\exp(iz)``.\n",
    "\n",
    "# Examples\n",
    "``jldoctest\n",
    "julia> cis(Ï€) â‰ˆ -1\n",
    "true\n",
    "``\n",
    "\"\"\"\n",
    "function cis(z::Complex)\n",
    "    v = exp(-imag(z))\n",
    "    s, c = sincos(real(z))\n",
    "    Complex(v * c, v * s)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    InitError(mod::Symbol, error)\n",
    "\n",
    "An error occurred when running a module's `__init__` function. The actual error thrown is\n",
    "available in the `.error` field.\n",
    "\"\"\"\n",
    "InitError\n",
    "\n",
    "\"\"\"\n",
    "    StridedVecOrMat{T}\n",
    "\n",
    "Union type of [`StridedVector`](@ref) and [`StridedMatrix`](@ref) with elements of type `T`.\n",
    "\"\"\"\n",
    "StridedVecOrMat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at different code snippets from the large agglomeration at the top of our UMAP visualization, represented in our cluster graphic as clusters 29, 13, 33, and 0 (from left to right). These clusters are all moderately short functions of similar complexity and layout, and these are found across all of our various code groups irrespective of purpose.\n",
    "\n",
    "Cluster 29:\n",
    "```Julia\n",
    "function userefs(@nospecialize(x))\n",
    "    relevant = x isa Expr && is_relevant_expr(x) || (x isa GotoIfNot || (x isa ReturnNode || (x isa PiNode || (x isa PhiNode || (x isa PhiCNode || x isa UpsilonNode)))))\n",
    "    return UseRefIterator(x, relevant)\n",
    "end\n",
    "\n",
    "function adce_erase!(phi_uses, extra_worklist, compact, idx)\n",
    "    if compact.result[idx] isa PhiNode\n",
    "        maybe_erase_unused!(extra_worklist, compact, idx, (val->begin\n",
    "                    phi_uses[val.id] -= 1\n",
    "                end))\n",
    "    else\n",
    "        maybe_erase_unused!(extra_worklist, compact, idx)\n",
    "    end\n",
    "end```\n",
    "\n",
    "Cluster 13:\n",
    "```Julia\n",
    "function gettypeinfos(io::IO, p::Pair)\n",
    "    typeinfo = get(io, :typeinfo, Any)\n",
    "    if p isa typeinfo <: Pair\n",
    "        fieldtype(typeinfo, 1) => fieldtype(typeinfo, 2)\n",
    "    else\n",
    "        Any => Any\n",
    "    end\n",
    "end\n",
    "\n",
    "function _maxlength(t::Tuple, t2::Tuple, t3::Tuple...)\n",
    "    @_inline_meta\n",
    "    max(length(t), _maxlength(t2, t3...))\n",
    "end\n",
    "\n",
    "function Base.deepcopy_internal(x::BigInt, stackdict::IdDict)\n",
    "    if haskey(stackdict, x)\n",
    "        return stackdict[x]\n",
    "    end\n",
    "    y = MPZ.set(x)\n",
    "    stackdict[x] = y\n",
    "    return y\n",
    "end```\n",
    "\n",
    "Cluster 33:\n",
    "```Julia\n",
    "function adduint64!(x::Bignum, operand::UInt64)\n",
    "    operand == 0 && return\n",
    "    other = Bignum()\n",
    "    assignuint64!(other, operand)\n",
    "    addbignum!(x, other)\n",
    "end\n",
    "\n",
    "function show(io::IO, r::LinRange)\n",
    "    print(io, \"\"range(\"\")\n",
    "    show(io, first(r))\n",
    "    print(io, \"\", stop=\"\")\n",
    "    show(io, last(r))\n",
    "    print(io, \"\", length=\"\")\n",
    "    show(io, length(r))\n",
    "    print(io, ')')\n",
    "end```\n",
    "\n",
    "Cluster 0:\n",
    "```Julia\n",
    "function length(s::AbstractString, i::Int, j::Int)\n",
    "    @boundscheck begin\n",
    "            0 < i â‰¤ ncodeunits(s) + 1 || throw(BoundsError(s, i))\n",
    "            0 â‰¤ j < ncodeunits(s) + 1 || throw(BoundsError(s, j))\n",
    "        end\n",
    "    n = 0\n",
    "    for k = i:j\n",
    "        @inbounds n += isvalid(s, k)\n",
    "    end\n",
    "    return n\n",
    "end\n",
    "\n",
    "function fma(x::BigFloat, y::BigFloat, z::BigFloat)\n",
    "    r = BigFloat()\n",
    "    ccall((\"mpfr_fma\", :libmpfr), Int32, (Ref{BigFloat}, Ref{BigFloat}, Ref{BigFloat}, Ref{BigFloat}, MPFRRoundingMode), r, x, y, z, ROUNDING_MODE[])\n",
    "    return r\n",
    "end```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Future Avenues for Research\n",
    "From this brief initial analysis, we can conclude a few things. First, as with other major programming languages previously tested, deep neural networks can in fact learn to recognize Julia code structures and content in potentially useful ways. Second, we confirm that UMAP clusters in our latent space successfully capture important characteristics of the code. And third - contrary to some of our prior expectations - while the latent representations of Julia source code capture important information and patterns in Julia expressions, these do not consistently point back to particular source code packages or groups in the Julia language ontology. Instead, these representations capture more low-level differencies and similarities, finding similar code structures that more often than not repeat across different regions of the code base. As with its human creators, there is much more difference within Julia source code groups than between them. \n",
    "\n",
    "Given these findings, it would be interesting to compare similar efforts with other languages to analyze how true this is across languages, or whether it is significantly more true in some languages than others. For instance, it would be interesting to explore if more parsimonious languages like Julia (or high level languages generally) exhibit the kind of wide disparity in syntactic patterns even within semantically similar code groups that we have seen here, while lower languages would see more syntactic similarity and semantic diversity. With respect to Julia code in particular and meta-modeling generally, we expect that further effort will enable us to leverage these embeddings for higher level tasks like recommending modifications, synthesizing models, identifying similar models, and validating the correctness of synthesized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
